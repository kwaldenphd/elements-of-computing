{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWrJSlabHGab9b4pO3Dgdz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Case Study: American Community Survey Data\n","\n","Let's look at an example of how we might utilize these workflows on an actual dataset, specifically <a href=\"https://data.census.gov/table/ACSST5Y2022.S1501?t=Education:Educational Attainment&g=050XX00US18141,18141$8600000&moe=false\">educational outcome attribute data from the American Community Survey</a>\n","  * [Link to download](https://raw.githubusercontent.com/kwaldenphd/elements-of-computing/main/book/data/ch6/data.csv)\n","  * *Note: I'm working with 2022's 5 year estimate, which I've renamed `data.csv`.*"],"metadata":{"id":"vDEa9oue3mTV"}},{"cell_type":"code","source":["import pandas as pd, re # import statements\n","df = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/elements-of-computing/main/book/data/ch5/data.csv\") # load data\n","df # show output"],"metadata":{"id":"0gHuIlMi45V5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A rich dataset, but not in particularly usable shape at the moment.\n"],"metadata":{"id":"vGVZuIii5BFm"}},{"cell_type":"markdown","source":["## Step #1: Building an Outline\n","\n","A good starting point is sketching out how you want the data to look at the end of reshaping operations. We can start thinking of this as the data processing version of pseudocode.\n","\n","For this dataset, you might want something like....\n","\n","| Area | Gender | Variable | Value |\n","| --- | --- | --- | --- |\n","| *geographic unit* | *gender breakdown* | *specific field* | *amount or measure* |\n","\n","Based on where the data is now, some things we might need to do...\n","- Break out the current column headers\n","- Make the updated column headers their own columns\n","- Probably relabel the columns to more user-friendly labels\n","\n","Let's dig in!"],"metadata":{"id":"_ip7lBDQ6iA-"}},{"cell_type":"markdown","source":["## Step #2: Splitting Column Headers\n","\n","Let's start splitting the column labels into a hierarchical index.\n","\n","We can use `!!` as a separator for regular expression string methods.\n","- [Click here](https://colab.research.google.com/drive/1Rd9KMoJ2AdtwVMNXwibakUbMGxz5Z6nM?usp=sharing#scrollTo=c1TKLsmiSS9N) for a Jupyter Notebook that provides a deep dive into regular expressions (regex) and string methods in Python."],"metadata":{"id":"jUOXk0AL5LWS"}},{"cell_type":"code","source":["df.columns = df.columns.str.split(\"!!\", 2, expand=True) # split column headers into multi-level index based on separator\n","df # show output"],"metadata":{"id":"LsGC0KPQ5kEb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we have a multi-index and can start to reshape this data."],"metadata":{"id":"P67hIQZL5muW"}},{"cell_type":"markdown","source":["## Step #3: Transposing the DataFrame\n","\n","Now, we can use `.transpose` to invert columns and rows."],"metadata":{"id":"AHeZktes5tOy"}},{"cell_type":"code","source":["df = df.T # transpose\n","df # show output"],"metadata":{"id":"EfnYPInp7Bxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We're making progress!"],"metadata":{"id":"h30z_Q6P7Fmo"}},{"cell_type":"markdown","source":["## Step #4: Reassign Header & Subset the Data\n","\n","We need the first row of data to serve as column headers. We can do this by subsetting our dataframe."],"metadata":{"id":"-gUEv7op7G4u"}},{"cell_type":"code","source":["header = df.iloc[0] # isolate first row to be new header\n","df = df[1:] # subset dataframe (everything past the first row)\n","df.columns = header # reassign headers\n","df # show output"],"metadata":{"id":"ZNd-eGVN7Pkn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step #5: Reindexing\n","\n","Right now, the area and coverage are part of a row multi-index. We can reset the index to make these columns."],"metadata":{"id":"Qk6NS_L489gn"}},{"cell_type":"code","source":["df = df.reset_index() # reset index\n","df # show output"],"metadata":{"id":"yKmw2ktU9JR5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We might also want to relabel some columns at this point."],"metadata":{"id":"Ndze-KJ49OVo"}},{"cell_type":"code","source":["df.columns.values[0] = 'area' # rename columns\n","df.columns.values[1] = 'coverage'\n","df.columns.values[2] = 'type'\n","df # show updated df"],"metadata":{"id":"Syg3vQLu9Tyo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step #6: Melting Variable Labels\n","\n","If our desired structure is\n","\n","| Area | Gender | Variable | Value |\n","| --- | --- | --- | --- |\n","| *geographic unit* | *gender breakdown* | *specific field* | *amount or measure* |\n","\n","<br>Then now might be a good time to melt the column labels."],"metadata":{"id":"2hEiUrS37V1B"}},{"cell_type":"code","source":["df = pd.melt(df, id_vars=['area', 'coverage', 'type']) # melt variable column\n","df.columns.values[3] = 'variable'\n","df # show output"],"metadata":{"id":"ikOeZsh17mMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"i_XX-f06-EOq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step #7: Subsetting & Filtering\n","\n","Last but not least, we might want to subset our `DataFrame` for meaningful columns, and remove rows with `NaN` values."],"metadata":{"id":"M2O-7z5c9xcF"}},{"cell_type":"code","source":["df = df[['area', 'coverage', 'variable', 'value']] # subset columns\n","df = df[df['value'].notnull()] # remove rows with NaN in value\n","df = df.reset_index(drop=True) # reset index\n","df['area'] = df['area'].str.replace(\"ZCTA5 \", \"\") # clean up area column to be able to join on zip code\n","df # show output"],"metadata":{"id":"HEVBqOoV-MJY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Wrap Up\n","\n","Voila! Let's see all of those steps together:"],"metadata":{"id":"74scNy3v-499"}},{"cell_type":"code","source":["import pandas as pd, re # import statements\n","df = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/elements-of-computing/main/book/data/ch5/data.csv\") # load data\n","\n","df.columns = df.columns.str.split(\"!!\", 2, expand=True) # split column headers into multi-level index based on separator\n","df = df.T # transpose\n","\n","header = df.iloc[0] # isolate first row to be new header\n","df = df[1:] # subset dataframe (everything past the first row)\n","df.columns = header # reassign headers\n","df = df.reset_index() # reset index\n","\n","df.columns.values[0] = 'area' # rename columns\n","df.columns.values[1] = 'coverage'\n","df.columns.values[2] = 'type'\n","\n","df = pd.melt(df, id_vars=['area', 'coverage', 'type']) # melt variable column\n","df.columns.values[3] = 'variable'\n","\n","df = df[['area', 'coverage', 'variable', 'value']] # subset columns\n","df = df[df['value'].notnull()] # remove rows with NaN in value\n","df = df.reset_index(drop=True) # reset index\n","df['area'] = df['area'].str.replace(\"ZCTA5 \", \"\") # clean up area column to be able to join on zip code\n","df # show output"],"metadata":{"id":"h94enSTA-_Fs"},"execution_count":null,"outputs":[]}]}